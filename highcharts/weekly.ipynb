{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weekly and EU data \n",
    "Add total for average, compute total and then the average\n",
    "Change the country's acronym for name\n",
    "A year has week 53 only if it ends on a Thursday or is a leap year and ends on a Wednesday.\n",
    "For example:\n",
    "2019 had a week 53 because it ended on a Tuesday.\n",
    "2020 and 2021 did not have week 53 because they ended on Thursday and Friday, respectively.\n",
    " - drop[ week 53\n",
    " - fill in missing weeks with interpolated values if you require all weeks to have values.]\n",
    "\n",
    "31/12/2018 week of 1 day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"src/data/analyzed/daily_demand_clean.csv\")\n",
    "\n",
    "#dropping UK for now\n",
    "df = df[df['country'] != 'UK']\n",
    "df['demand'] = df['demand'] / 1000000000   #convert to TWh\n",
    "df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "df['week'] = df['date'].dt.isocalendar().week #week \n",
    "df['year'] = df['date'].dt.isocalendar().year  # Use ISO year to avoid mismatches at year boundaries e.g. year(31/12/2018) = 2019\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'week' and all other relevant variables, then count the number of observations per group\n",
    "group_columns = ['week', 'year', 'country', 'type']  # Adjust these based on your DataFrame's structure\n",
    "df['count'] = df.groupby(group_columns)['demand'].transform('count')\n",
    "\n",
    "\n",
    "\n",
    "# Filter rows where the count is 7 or more\n",
    "df = df[df['count'] == 7]\n",
    "\n",
    "# Drop the helper 'count' column if no longer needed\n",
    "df = df.drop(columns=['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum total; industry etc to get a European value\n",
    "df_europe = df.groupby(['type', 'year', 'week', 'date' ])['demand'].sum().reset_index()\n",
    "df_europe['country'] = 'Europe'  # Assign country as \"Europe\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df_europe], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UInt32\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df['year'].dtype)\n",
    "print(df['year'].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weekly = df.groupby(['country', 'type', 'year', 'week'])['demand'].sum().reset_index()\n",
    "df_weekly = df_weekly[df_weekly['year'] >= 2019]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the years to average\n",
    "years_to_average = [2019, 2020, 2021]\n",
    "\n",
    "# Filter for rows corresponding to the specified years\n",
    "filtered_df = df_weekly[df_weekly['year'].isin(years_to_average)]\n",
    "\n",
    "# Group by type, week, and country, then calculate the average demand\n",
    "average_df = (\n",
    "    filtered_df\n",
    "    .groupby(['type', 'week','country'], as_index=False)\n",
    "    .agg({'demand': 'mean'})\n",
    ")\n",
    "\n",
    "# Add a new column for the year and set it to \"AVG-2019-2021\"\n",
    "average_df['year'] = \"AVG-2019-2021\"\n",
    "\n",
    "# Subset 2: Keep rows that are not part of the specified years\n",
    "remaining_years_df = df_weekly[~df_weekly['year'].isin(years_to_average)]\n",
    "\n",
    "# Fianl subset: Combine the subsets \n",
    "df_with_average = pd.concat([remaining_years_df, average_df], ignore_index=True)\n",
    "# Replace all 0s in the 'demand' column with NaN\n",
    "df_with_average['demand'] = df_with_average['demand'].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'country_full'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\marie.juge\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'country_full'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m df_with_average[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcountry\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df_with_average[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcountry\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(country_mapping)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Create the 'countryType' column with full country names\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m df_with_average[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcountryType\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_with_average\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcountry_full\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m df_with_average[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\marie.juge\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\marie.juge\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'country_full'"
     ]
    }
   ],
   "source": [
    "# Define a mapping of EU country codes to their full names\n",
    "country_mapping = {\n",
    "    \"AT\": \"Austria\", \"BE\": \"Belgium\", \"BG\": \"Bulgaria\", \"HR\": \"Croatia\", \n",
    "    \"CY\": \"Cyprus\", \"CZ\": \"Czech Republic\", \"DK\": \"Denmark\", \"EE\": \"Estonia\", \n",
    "    \"FI\": \"Finland\", \"FR\": \"France\", \"DE\": \"Germany\", \"GR\": \"Greece\", \n",
    "    \"HU\": \"Hungary\", \"IS\": \"Iceland\", \"IE\": \"Ireland\", \"IT\": \"Italy\", \n",
    "    \"LV\": \"Latvia\", \"LI\": \"Liechtenstein\", \"LT\": \"Lithuania\", \"LU\": \"Luxembourg\", \n",
    "    \"MT\": \"Malta\", \"NL\": \"Netherlands\", \"NO\": \"Norway\", \"PL\": \"Poland\", \n",
    "    \"PT\": \"Portugal\", \"RO\": \"Romania\", \"SK\": \"Slovakia\", \"SI\": \"Slovenia\", \n",
    "    \"ES\": \"Spain\", \"SE\": \"Sweden\", \"CH\": \"Switzerland\", \"TR\": \"Turkey\", \n",
    "    \"UK\": \"United Kingdom\", \"Europe\": \"xEU\"\n",
    "}\n",
    "\n",
    "# Replace country codes with full names\n",
    "df_with_average[\"country\"] = df_with_average[\"country\"].map(country_mapping)\n",
    "\n",
    "# Create the 'countryType' column with full country names\n",
    "df_with_average[\"countryType\"] = df_with_average[\"country\"] + \" - \" + df_with_average[\"type\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file has been saved as: src/data/analyzed/weekly_demand_clean.json\n"
     ]
    }
   ],
   "source": [
    "# Save to a JSON file\n",
    "\n",
    "file_path = \"highcharts/data/weekly_demand_clean.json\"\n",
    "df_with_average.to_json(file_path, orient='records', indent=4)\n",
    "print(f\"The file has been saved as: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: AT, Type: power\n",
      "Country: AT, Type: total\n",
      "Country: BE, Type: household\n",
      "Country: BE, Type: industry\n",
      "Country: BE, Type: power\n",
      "Country: BE, Type: total\n",
      "Country: BG, Type: power\n",
      "Country: BG, Type: total\n",
      "Country: CZ, Type: power\n",
      "Country: DE, Type: power\n",
      "Country: DE, Type: total\n",
      "Country: DK, Type: power\n",
      "Country: DK, Type: total\n",
      "Country: EE, Type: power\n",
      "Country: EE, Type: total\n",
      "Country: ES, Type: power\n",
      "Country: ES, Type: total\n",
      "Country: Europe, Type: household\n",
      "Country: Europe, Type: industry\n",
      "Country: Europe, Type: industry-power\n",
      "Country: Europe, Type: power\n",
      "Country: Europe, Type: total\n",
      "Country: FI, Type: power\n",
      "Country: FR, Type: household\n",
      "Country: FR, Type: industry\n",
      "Country: FR, Type: power\n",
      "Country: FR, Type: total\n",
      "Country: GR, Type: power\n",
      "Country: HR, Type: power\n",
      "Country: HR, Type: total\n",
      "Country: HU, Type: household\n",
      "Country: HU, Type: industry\n",
      "Country: HU, Type: industry-power\n",
      "Country: HU, Type: power\n",
      "Country: HU, Type: total\n",
      "Country: IT, Type: household\n",
      "Country: IT, Type: industry\n",
      "Country: IT, Type: power\n",
      "Country: IT, Type: total\n",
      "Country: LT, Type: power\n",
      "Country: LU, Type: household\n",
      "Country: LU, Type: industry\n",
      "Country: LU, Type: industry-power\n",
      "Country: LU, Type: power\n",
      "Country: LU, Type: total\n",
      "Country: LV, Type: power\n",
      "Country: LV, Type: total\n",
      "Country: NL, Type: household\n",
      "Country: NL, Type: industry\n",
      "Country: NL, Type: power\n",
      "Country: NL, Type: total\n",
      "Country: PL, Type: power\n",
      "Country: PL, Type: total\n",
      "Country: PT, Type: household\n",
      "Country: PT, Type: industry\n",
      "Country: PT, Type: industry-power\n",
      "Country: PT, Type: power\n",
      "Country: PT, Type: total\n",
      "Country: RO, Type: household\n",
      "Country: RO, Type: industry\n",
      "Country: RO, Type: industry-power\n",
      "Country: RO, Type: power\n",
      "Country: RO, Type: total\n",
      "Country: SE, Type: power\n",
      "Country: SI, Type: power\n",
      "Country: SI, Type: total\n",
      "Country: SK, Type: power\n"
     ]
    }
   ],
   "source": [
    "for (country, type_), group in df_with_average.groupby(['country', 'type']):\n",
    "    print(f\"Country: {country}, Type: {type_}\")\n",
    "    \n",
    "    group_pivot = group.pivot_table(index='week', columns='year', values='demand', aggfunc='sum')\n",
    "    \n",
    "    try:\n",
    "        if \"AVG-2019-2021\" in group_pivot.columns:\n",
    "            plt.plot(group_pivot.index, group_pivot[\"AVG-2019-2021\"], \n",
    "                     label='AVG-2019-2021', color='grey', linestyle='-', linewidth=1.8, alpha=0.8)\n",
    "\n",
    "        if 2022 in group_pivot.columns:\n",
    "            plt.plot(group_pivot.index, group_pivot[2022], \n",
    "                     label='2022', color='grey', linestyle='-', linewidth=1.8, alpha=0.8)\n",
    "\n",
    "        if 2023 in group_pivot.columns:\n",
    "            plt.plot(group_pivot.index, group_pivot[2023], \n",
    "                     label='2023', color='#D5727D', linestyle='-', linewidth=2)\n",
    "\n",
    "        if 2024 in group_pivot.columns:\n",
    "            plt.plot(group_pivot.index, group_pivot[2024], \n",
    "                     label='2024', color='#C02C44', linestyle='-', linewidth=2.5)\n",
    "\n",
    "        group_pivot_2025 = group_pivot.loc[group_pivot.index <= 2]\n",
    "        if 2025 in group_pivot_2025.columns:\n",
    "            plt.plot(group_pivot_2025.index, group_pivot_2025[2025], \n",
    "                     label='2025', color='#A21636', linestyle='-', linewidth=3)\n",
    "\n",
    "        # Customize legend and plot title\n",
    "        plt.legend(title=\"Year\", loc='best', fontsize=10, title_fontsize=12, frameon=False)\n",
    "        plt.title(f'{country}-{type_} weekly natural gas demand (TWh)')\n",
    "        plt.ylim(0)\n",
    "        \n",
    "        # Save the figure\n",
    "        plt.savefig(f'src/figures/weekly/{country}_{type_}.png', bbox_inches='tight', dpi=300)\n",
    "        plt.close()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {country}-{type_}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
