{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#data that has had initial cleaning performed on it\n",
    "df = pd.read_json(\"src/data/analyzed/monthly_demand_clean.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping of EU country codes to their full names\n",
    "country_mapping = {\n",
    "    \"AT\": \"Austria\", \"BE\": \"Belgium\", \"BG\": \"Bulgaria\", \"HR\": \"Croatia\", \n",
    "    \"CY\": \"Cyprus\", \"CZ\": \"Czech Republic\", \"DK\": \"Denmark\", \"EE\": \"Estonia\", \n",
    "    \"FI\": \"Finland\", \"FR\": \"France\", \"DE\": \"Germany\", \"GR\": \"Greece\", \n",
    "    \"HU\": \"Hungary\", \"IS\": \"Iceland\", \"IE\": \"Ireland\", \"IT\": \"Italy\", \n",
    "    \"LV\": \"Latvia\", \"LI\": \"Liechtenstein\", \"LT\": \"Lithuania\", \"LU\": \"Luxembourg\", \n",
    "    \"MT\": \"Malta\", \"NL\": \"Netherlands\", \"NO\": \"Norway\", \"PL\": \"Poland\", \n",
    "    \"PT\": \"Portugal\", \"RO\": \"Romania\", \"SK\": \"Slovakia\", \"SI\": \"Slovenia\", \n",
    "    \"ES\": \"Spain\", \"SE\": \"Sweden\", \"CH\": \"Switzerland\", \"TR\": \"Turkey\", \n",
    "    \"UK\": \"United Kingdom\", \"EU\": \"Europe*\"\n",
    "}\n",
    "\n",
    "# Replace country codes with full names\n",
    "df[\"country_full\"] = df[\"country\"].map(country_mapping)\n",
    "df[\"country\"] = df[\"country_full\"]\n",
    "\n",
    "# Create the 'countryType' column with full country names\n",
    "df[\"country_type\"] = df[\"country_full\"] + \" - \" + df[\"type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the years to average\n",
    "years_to_average = [2019, 2020, 2021]\n",
    "\n",
    "# Filter for rows corresponding to the specified years\n",
    "filtered_df = df[df['year'].isin(years_to_average)]\n",
    "\n",
    "# Group by country, type, and month, then calculate the average demand\n",
    "index_df = (\n",
    "    filtered_df\n",
    "    .groupby(['country', 'type', 'month'])['demand']\n",
    "    .mean()\n",
    "    .reset_index(name='monthly_index')  # Calculate the average demand\n",
    ")\n",
    "\n",
    "\n",
    "df= df.merge(index_df, on=['country', 'type', 'month'], how='left')\n",
    "\n",
    "\n",
    "# Group by type, week, and country, then calculate the average demand\n",
    "average_df = (\n",
    "    filtered_df\n",
    "    .groupby(['type', 'month','country'])['demand']\n",
    "    .mean()\n",
    "    .reset_index(name='demand_average') \n",
    ")\n",
    "\n",
    "# Add a new column for the year and set it to \"AVG-2019-2021\"\n",
    "average_df['year'] = \"AVG-2019-2021\"\n",
    "df[\"demand_average\"] =df[\"demand\"]\n",
    "df= pd.concat([df, average_df], ignore_index=True)\n",
    "\n",
    "# Replace all 0s in the 'demand' column with NaN\n",
    "#df['demand_average'] = df['demand_average'].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate indexed demand values for all rows except \"AVG-2019-2021\"\n",
    "df['demand_sector'] = (df['demand'] - df['monthly_index'])\n",
    "df['demand_indexed'] = (df['demand'] / df['monthly_index'])*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexed Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i = df.copy()\n",
    "index_df_i = index_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_i[\"month\"] = df_i[\"month\"].astype(str).str.zfill(2)  # Add leading zero to month if needed\n",
    "df_i[\"year\"] = df_i[\"year\"].astype(str)\n",
    "\n",
    "# Create the new column 'monthb' as a concatenation of 'month' and 'year'\n",
    "df_i[\"x_value\"] =  df_i[\"month\"] + \"/\"+ df_i[\"year\"]\n",
    "\n",
    "#Drop type=total\n",
    "# Remove rows with years 2019, 2020, or 2021\n",
    "df_i= df_i[~df_i['year'].isin(years_to_average)]\n",
    "df_i = df_i[df_i['type'] == 'total'].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s = df.copy()\n",
    "index_df_s = index_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s = df_s[df_s['type'] != \"total\"]\n",
    "df_s[\"month\"] = df_s[\"month\"].astype(str).str.zfill(2)  # Ensure two-digit month\n",
    "df_s[\"year\"] = df_s[\"year\"].astype(str)  # Ensure year is string\n",
    "df_s[\"x_value\"] = df_s[\"month\"] + \"/\" + df_s[\"year\"]  # Format as \"MM/YYYY\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file has been saved as: highcharts/data/monthly_demand_average.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "df_a = df.copy()\n",
    "index_df_a = index_df.copy()\n",
    "\n",
    "\n",
    "\n",
    "df_a = df_a[~df_a['year'].isin([2019, 2020, 2021])]\n",
    "\n",
    "df_a[\"month\"] = df_a[\"month\"].astype(str).str.zfill(2)  # Ensure two-digit month\n",
    "df_a[\"year\"] = df_a[\"year\"].astype(str)  # Ensure year is strin\n",
    "\n",
    "df_json = df_a.copy()\n",
    "df_json[\"y_value\"] = df_json[\"demand_average\"]\n",
    "\n",
    "\n",
    "\n",
    "# Now apply rounding safely\n",
    "df_json[\"y_value\"] = df_json[\"y_value\"].round(2)\n",
    "\n",
    "\n",
    "df_json[\"x_value\"] = df_json[\"year\"]\n",
    "df_json[\"x_b_value\"] = df_json[\"month\"]\n",
    "df_json[\"group_value\"] = df_json[\"type\"]\n",
    "df_json[\"group_b_value\"] = df_json[\"country\"]\n",
    "\n",
    "\n",
    "\n",
    "# Keep only required columns\n",
    "df_json = df_json[[\"x_value\", \"y_value\", \"x_b_value\", \"group_value\", \"group_b_value\"]]\n",
    "\n",
    "# Convert all known NaN representations to actual NaN (ensuring full detection)\n",
    "df_json.replace({\"\": None, \"NaN\": None, \"nan\": None, \"NULL\": None, pd.NA: None, float(\"nan\"): None}, inplace=True)\n",
    "\n",
    "\n",
    "# Drop all rows where y_value is NaN, None, or missing\n",
    "df_json = df_json.dropna(subset=[\"y_value\"])  # Ensures only valid rows remain\n",
    "\n",
    "# Drop all rows where y_value is NaN, None, or missing\n",
    "df_json = df_json.dropna(subset=[\"y_value\"])  # Ensures only valid rows remain\n",
    "\n",
    "# Convert DataFrame to JSON format (forces NaN to be removed)\n",
    "json_data = df_json.to_dict(orient=\"records\")\n",
    "\n",
    "# Save JSON without escaping forward slashes\n",
    "file_path = \"highcharts/data/monthly_demand_average.json\"\n",
    "with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(json_data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "\n",
    "print(f\"The file has been saved as: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a copy to avoid modifying df_s in place\n",
    "df_json = df_s.copy()\n",
    "\n",
    "# Rename columns to match output structure\n",
    "df_json[\"y_value\"] = df_json[\"demand_sector\"]\n",
    "df_json[\"y_value\"] = df_json[\"y_value\"].round(2)\n",
    "df_json[\"group_value\"] = df_json[\"type\"]\n",
    "df_json[\"group_b_value\"] = df_json[\"country\"]\n",
    "\n",
    "df_json = df_json[[\"x_value\", \"y_value\", \"group_value\", \"group_b_value\"]]\n",
    "# Convert all known NaN representations to actual NaN (ensuring full detection)\n",
    "df_json.replace({\"\": None, \"NaN\": None, \"nan\": None, \"NULL\": None, pd.NA: None, float(\"nan\"): None}, inplace=True)\n",
    "\n",
    "# Drop all rows where y_value is NaN, None, or missing\n",
    "df_json = df_json.dropna(subset=[\"y_value\"])  # Ensures only valid rows remain\n",
    "\n",
    "# Convert DataFrame to JSON format (forces NaN to be removed)\n",
    "json_data = df_json.to_dict(orient=\"records\")\n",
    "\n",
    "# Save JSON without escaping forward slashes\n",
    "file_path = \"highcharts/data/monthly_demand_sector.json\"\n",
    "with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(json_data, f, indent=4, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file has been saved as: highcharts/data/monthly_demand_indexed.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marie.juge\\AppData\\Local\\Temp\\ipykernel_14360\\4200743194.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_json[\"y_value\"].replace([np.inf, -np.inf], np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_json = df_i.copy()\n",
    "df_json[\"y_value\"] = df_json[\"demand_indexed\"]\n",
    "\n",
    "\n",
    "# Replace infinite values with NaN before rounding\n",
    "df_json[\"y_value\"].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Now apply rounding safely\n",
    "df_json[\"y_value\"] = df_json[\"y_value\"].round(2)\n",
    "\n",
    "df_json[\"group_value\"] = df_json[\"country\"]\n",
    "\n",
    "df_json[df_json['type'] == 'total']\n",
    "# Keep only required columns\n",
    "df_json = df_json[[\"x_value\", \"y_value\", \"group_value\"]]\n",
    "\n",
    "# Convert all known NaN representations to actual NaN (ensuring full detection)\n",
    "df_json.replace({\"\": None, \"NaN\": None, \"nan\": None, \"NULL\": None, pd.NA: None, float(\"nan\"): None}, inplace=True)\n",
    "\n",
    "\n",
    "# Drop all rows where y_value is NaN, None, or missing\n",
    "df_json = df_json.dropna(subset=[\"y_value\"])  # Ensures only valid rows remain\n",
    "\n",
    "\n",
    "# Convert DataFrame to JSON format (forces NaN to be removed)\n",
    "json_data = df_json.to_dict(orient=\"records\")\n",
    "\n",
    "# Save JSON without escaping forward slashes\n",
    "file_path = \"highcharts/data/monthly_demand_indexed.json\"\n",
    "with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(json_data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "\n",
    "print(f\"The file has been saved as: {file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
