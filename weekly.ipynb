{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weekly and EU data \n",
    "Add total for average, compute total and then the average\n",
    "Change the country's acronym for name\n",
    "A year has week 53 only if it ends on a Thursday or is a leap year and ends on a Wednesday.\n",
    "For example:\n",
    "2019 had a week 53 because it ended on a Tuesday.\n",
    "2020 and 2021 did not have week 53 because they ended on Thursday and Friday, respectively.\n",
    " - drop[ week 53\n",
    " - fill in missing weeks with interpolated values if you require all weeks to have values.]\n",
    "\n",
    "31/12/2018 week of 1 day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"src/data/analyzed/daily_demand_clean.csv\")\n",
    "\n",
    "#dropping UK for now\n",
    "df = df[df['country'] != 'UK']\n",
    "df['demand'] = df['demand'] / 1000000000   #convert to TWh\n",
    "df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "df['week'] = df['date'].dt.isocalendar().week #week \n",
    "df['year'] = df['date'].dt.isocalendar().year  # Use ISO year to avoid mismatches at year boundaries e.g. year(31/12/2018) = 2019\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'week' and all other relevant variables, then count the number of observations per group\n",
    "group_columns = ['week', 'year', 'country', 'type']  # Adjust these based on your DataFrame's structure\n",
    "df['count'] = df.groupby(group_columns)['demand'].transform('count')\n",
    "\n",
    "\n",
    "\n",
    "# Filter rows where the count is 7 or more\n",
    "df = df[df['count'] == 7]\n",
    "\n",
    "# Drop the helper 'count' column if no longer needed\n",
    "df = df.drop(columns=['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum total; industry etc to get a European value\n",
    "df_europe = df.groupby(['type', 'year', 'week', 'date' ])['demand'].sum().reset_index()\n",
    "df_europe['country'] = 'Europe'  # Assign country as \"Europe\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df_europe], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UInt32\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df['year'].dtype)\n",
    "print(df['year'].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weekly = df.groupby(['country', 'type', 'year', 'week'])['demand'].sum().reset_index()\n",
    "df_weekly = df_weekly[df_weekly['year'] >= 2019]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the years to average\n",
    "years_to_average = [2019, 2020, 2021]\n",
    "\n",
    "# Filter for rows corresponding to the specified years\n",
    "filtered_df = df_weekly[df_weekly['year'].isin(years_to_average)]\n",
    "\n",
    "# Group by type, week, and country, then calculate the average demand\n",
    "average_df = (\n",
    "    filtered_df\n",
    "    .groupby(['type', 'week','country'], as_index=False)\n",
    "    .agg({'demand': 'mean'})\n",
    ")\n",
    "\n",
    "# Add a new column for the year and set it to \"AVG-2019-2021\"\n",
    "average_df['year'] = \"AVG-2019-2021\"\n",
    "\n",
    "# Subset 2: Keep rows that are not part of the specified years\n",
    "remaining_years_df = df_weekly[~df_weekly['year'].isin(years_to_average)]\n",
    "\n",
    "# Fianl subset: Combine the subsets \n",
    "df_with_average = pd.concat([remaining_years_df, average_df], ignore_index=True)\n",
    "# Replace all 0s in the 'demand' column with NaN\n",
    "df_with_average['demand'] = df_with_average['demand'].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping of EU country codes to their full names\n",
    "country_mapping = {\n",
    "    \"AT\": \"Austria\", \"BE\": \"Belgium\", \"BG\": \"Bulgaria\", \"HR\": \"Croatia\", \n",
    "    \"CY\": \"Cyprus\", \"CZ\": \"Czech Republic\", \"DK\": \"Denmark\", \"EE\": \"Estonia\", \n",
    "    \"FI\": \"Finland\", \"FR\": \"France\", \"DE\": \"Germany\", \"GR\": \"Greece\", \n",
    "    \"HU\": \"Hungary\", \"IS\": \"Iceland\", \"IE\": \"Ireland\", \"IT\": \"Italy\", \n",
    "    \"LV\": \"Latvia\", \"LI\": \"Liechtenstein\", \"LT\": \"Lithuania\", \"LU\": \"Luxembourg\", \n",
    "    \"MT\": \"Malta\", \"NL\": \"Netherlands\", \"NO\": \"Norway\", \"PL\": \"Poland\", \n",
    "    \"PT\": \"Portugal\", \"RO\": \"Romania\", \"SK\": \"Slovakia\", \"SI\": \"Slovenia\", \n",
    "    \"ES\": \"Spain\", \"SE\": \"Sweden\", \"CH\": \"Switzerland\", \"TR\": \"Turkey\", \n",
    "    \"UK\": \"United Kingdom\", \"Europe\": \"xEU\"\n",
    "}\n",
    "\n",
    "# Replace country codes with full names\n",
    "df_with_average[\"country\"] = df_with_average[\"country\"].map(country_mapping)\n",
    "\n",
    "# Create the 'countryType' column with full country names\n",
    "df_with_average[\"countryType\"] = df_with_average[\"country\"] + \" - \" + df_with_average[\"type\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json = df_with_average.copy()\n",
    "df_json[\"y_value\"] = df_json.pop(\"demand\")\n",
    "df_json[\"group_value\"] = df_json.pop(\"type\")\n",
    "df_json[\"group_b_value\"] = df_json.pop(\"country\")\n",
    "df_json[\"x_value\"] = df_json.pop(\"year\")\n",
    "df_json[\"x_b_value\"] = df_json.pop(\"week\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file has been saved as: highcharts/data/weekly_demand.json\n"
     ]
    }
   ],
   "source": [
    "# Save to a JSON file\n",
    "\n",
    "file_path = \"highcharts/data/weekly_demand.json\"\n",
    "df_json.to_json(file_path, orient='records', indent=4)\n",
    "print(f\"The file has been saved as: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: Austria, Type: power\n",
      "Country: Austria, Type: total\n",
      "Country: Belgium, Type: household\n",
      "Country: Belgium, Type: industry\n",
      "Country: Belgium, Type: power\n",
      "Country: Belgium, Type: total\n",
      "Country: Bulgaria, Type: power\n",
      "Country: Bulgaria, Type: total\n",
      "Country: Croatia, Type: power\n",
      "Country: Croatia, Type: total\n",
      "Country: Czech Republic, Type: power\n",
      "Country: Denmark, Type: power\n",
      "Country: Denmark, Type: total\n",
      "Country: Estonia, Type: power\n",
      "Country: Estonia, Type: total\n",
      "Country: Finland, Type: power\n",
      "Country: France, Type: household\n",
      "Country: France, Type: industry\n",
      "Country: France, Type: power\n",
      "Country: France, Type: total\n",
      "Country: Germany, Type: power\n",
      "Country: Germany, Type: total\n",
      "Country: Greece, Type: power\n",
      "Country: Hungary, Type: household\n",
      "Country: Hungary, Type: industry\n",
      "Country: Hungary, Type: industry-power\n",
      "Country: Hungary, Type: power\n",
      "Country: Hungary, Type: total\n",
      "Country: Italy, Type: household\n",
      "Country: Italy, Type: industry\n",
      "Country: Italy, Type: power\n",
      "Country: Italy, Type: total\n",
      "Country: Latvia, Type: power\n",
      "Country: Latvia, Type: total\n",
      "Country: Lithuania, Type: power\n",
      "Country: Luxembourg, Type: household\n",
      "Country: Luxembourg, Type: industry\n",
      "Country: Luxembourg, Type: industry-power\n",
      "Country: Luxembourg, Type: power\n",
      "Country: Luxembourg, Type: total\n",
      "Country: Netherlands, Type: household\n",
      "Country: Netherlands, Type: industry\n",
      "Country: Netherlands, Type: power\n",
      "Country: Netherlands, Type: total\n",
      "Country: Poland, Type: power\n",
      "Country: Poland, Type: total\n",
      "Country: Portugal, Type: household\n",
      "Country: Portugal, Type: industry\n",
      "Country: Portugal, Type: industry-power\n",
      "Country: Portugal, Type: power\n",
      "Country: Portugal, Type: total\n",
      "Country: Romania, Type: household\n",
      "Country: Romania, Type: industry\n",
      "Country: Romania, Type: industry-power\n",
      "Country: Romania, Type: power\n",
      "Country: Romania, Type: total\n",
      "Country: Slovakia, Type: power\n",
      "Country: Slovenia, Type: power\n",
      "Country: Slovenia, Type: total\n",
      "Country: Spain, Type: power\n",
      "Country: Spain, Type: total\n",
      "Country: Sweden, Type: power\n",
      "Country: xEU, Type: household\n",
      "Country: xEU, Type: industry\n",
      "Country: xEU, Type: industry-power\n",
      "Country: xEU, Type: power\n",
      "Country: xEU, Type: total\n"
     ]
    }
   ],
   "source": [
    "for (country, type_), group in df_with_average.groupby(['country', 'type']):\n",
    "    print(f\"Country: {country}, Type: {type_}\")\n",
    "    \n",
    "    group_pivot = group.pivot_table(index='week', columns='year', values='demand', aggfunc='sum')\n",
    "    \n",
    "    try:\n",
    "        if \"AVG-2019-2021\" in group_pivot.columns:\n",
    "            plt.plot(group_pivot.index, group_pivot[\"AVG-2019-2021\"], \n",
    "                     label='AVG-2019-2021', color='grey', linestyle='-', linewidth=1.8, alpha=0.8)\n",
    "\n",
    "        if 2022 in group_pivot.columns:\n",
    "            plt.plot(group_pivot.index, group_pivot[2022], \n",
    "                     label='2022', color='grey', linestyle='-', linewidth=1.8, alpha=0.8)\n",
    "\n",
    "        if 2023 in group_pivot.columns:\n",
    "            plt.plot(group_pivot.index, group_pivot[2023], \n",
    "                     label='2023', color='#D5727D', linestyle='-', linewidth=2)\n",
    "\n",
    "        if 2024 in group_pivot.columns:\n",
    "            plt.plot(group_pivot.index, group_pivot[2024], \n",
    "                     label='2024', color='#C02C44', linestyle='-', linewidth=2.5)\n",
    "\n",
    "        group_pivot_2025 = group_pivot.loc[group_pivot.index <= 2]\n",
    "        if 2025 in group_pivot_2025.columns:\n",
    "            plt.plot(group_pivot_2025.index, group_pivot_2025[2025], \n",
    "                     label='2025', color='#A21636', linestyle='-', linewidth=3)\n",
    "\n",
    "        # Customize legend and plot title\n",
    "        plt.legend(title=\"Year\", loc='best', fontsize=10, title_fontsize=12, frameon=False)\n",
    "        plt.title(f'{country}-{type_} weekly natural gas demand (TWh)')\n",
    "        plt.ylim(0)\n",
    "        \n",
    "        # Save the figure\n",
    "        plt.savefig(f'src/figures/weekly/{country}_{type_}.png', bbox_inches='tight', dpi=300)\n",
    "        plt.close()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {country}-{type_}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
